{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config IPython.matplotlib.backend = \"retina\"\n",
    "from matplotlib import rcParams\n",
    "rcParams[\"savefig.dpi\"] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asteroseismology in the time domain\n",
    "\n",
    "This notebook show an example of fitting the asteorseismic oscillations in some time series photometry for a giant star from Kepler with a Gaussian Process model. The point of this notebook is to show that, when fitting in the time domain, it is possible to recover probabilistic estimates of $\\nu_\\mathrm{max}$ and $\\Delta \\nu$ with a shorter dataset than the one needed by the standard periodogram-based methods.\n",
    "\n",
    "First import eveything we'll need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import kplr\n",
    "import corner\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "\n",
    "import emcee3\n",
    "from emcee3 import autocorr\n",
    "\n",
    "from astropy.stats import LombScargle\n",
    "\n",
    "import genrp\n",
    "from genrp import kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def format_filename(name):\n",
    "    base = os.path.join(\"astero\", \"{0}\".format(kicid))\n",
    "    os.makedirs(base, exist_ok=True)\n",
    "    return os.path.join(base, name + \".pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's download the data for a giant star from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# kicid = 3955067\n",
    "kicid = 11615890\n",
    "\n",
    "client = kplr.API()\n",
    "star = client.star(kicid)\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "yerr = []\n",
    "\n",
    "for lc in star.get_light_curves():\n",
    "    data = lc.read()\n",
    "    x0 = data[\"TIME\"]\n",
    "    y0 = data[\"PDCSAP_FLUX\"]\n",
    "    m = (data[\"SAP_QUALITY\"] == 0) & np.isfinite(x0) & np.isfinite(y0)\n",
    "    x.append(x0[m])\n",
    "    mu = np.median(y0[m])\n",
    "    y.append((y0[m] / mu - 1.0) * 1e6)\n",
    "    yerr.append(1e6 * data[\"PDCSAP_FLUX_ERR\"][m] / mu)\n",
    "\n",
    "x = np.concatenate(x)\n",
    "y = np.concatenate(y)\n",
    "yerr = np.concatenate(yerr)\n",
    "\n",
    "inds = np.argsort(x)\n",
    "x = np.ascontiguousarray(x[inds], dtype=float)\n",
    "y = np.ascontiguousarray(y[inds], dtype=float)\n",
    "yerr = np.ascontiguousarray(yerr[inds], dtype=float)\n",
    "\n",
    "plt.plot(x, y, \"k\", rasterized=True)\n",
    "plt.xlim(x.min(), x.max())\n",
    "plt.xlabel(\"time [KBJD]\")\n",
    "plt.ylabel(\"rel.\\ flux [ppm]\")\n",
    "plt.savefig(format_filename(\"time_series\"), bbox_inches=\"tight\", dpi=300);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a frequency grid for the periodogram\n",
    "freq_uHz = np.linspace(1, 300, 50000)\n",
    "freq = freq_uHz * 1e-6 * 24 * 60 * 60\n",
    "\n",
    "# Compute the periodogram on the full dataset\n",
    "model = LombScargle(x, y)\n",
    "power_all = model.power(freq, method=\"fast\", normalization=\"psd\")\n",
    "\n",
    "# Select a subset of the data\n",
    "np.random.seed(1234)\n",
    "n = int(30 * 48)\n",
    "n0 = np.random.randint(len(x)-n-1)\n",
    "fit_x, fit_y, fit_yerr = x[n0:n0+n], y[n0:n0+n], yerr[n0:n0+n]\n",
    "print(\"Range in subset of data: {0:.1f} days\".format(fit_x.max() - fit_x.min()))\n",
    "print(\"Fraction of full dataset: {0:.1f}%\".format(100 * n / len(x)))\n",
    "\n",
    "# Compute the periodogram on the subset\n",
    "model = LombScargle(fit_x, fit_y)\n",
    "power_some = model.power(freq, method=\"fast\", normalization=\"psd\")\n",
    "\n",
    "# Remove background from periodograms\n",
    "def estimate_background(x, y, log_width=0.005):\n",
    "    count = np.zeros(len(x), dtype=int)\n",
    "    bkg = np.zeros_like(x)\n",
    "    x0 = np.log10(x[0])\n",
    "    while x0 < np.log10(x[-1]):\n",
    "        m = np.abs(np.log10(x) - x0) < log_width\n",
    "        bkg[m] += np.median(y[m])\n",
    "        count[m] += 1\n",
    "        x0 += 0.5 * log_width\n",
    "    return bkg / count\n",
    "bkg_all = estimate_background(freq_uHz, power_all)\n",
    "bkg_some = estimate_background(freq_uHz, power_some)\n",
    "\n",
    "# Plot the periodograms\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 3), sharey=True)\n",
    "axes[0].plot(freq_uHz, power_all, \"k\", rasterized=True)\n",
    "axes[1].plot(freq_uHz, power_some, \"k\", rasterized=True)\n",
    "axes[0].set_ylabel(\"periodogram\")\n",
    "axes[0].set_xlabel(\"frequency [$\\mu$Hz]\")\n",
    "axes[1].set_xlabel(\"frequency [$\\mu$Hz]\")\n",
    "axes[0].set_title(\"all data\")\n",
    "axes[1].set_title(\"subset of data\")\n",
    "[ax.set_yscale(\"log\") for ax in axes];\n",
    "fig.savefig(format_filename(\"periodogram\"), bbox_inches=\"tight\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = LombScargle(x, np.ones_like(y), fit_mean=False, center_data=False)\n",
    "window_all = model.power(freq, method=\"fast\", normalization=\"psd\")\n",
    "model = LombScargle(fit_x, np.ones_like(fit_y), fit_mean=False, center_data=False)\n",
    "window_some = model.power(freq, method=\"fast\", normalization=\"psd\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 3), sharey=True)\n",
    "axes[0].plot(freq_uHz, window_all, \"k\", rasterized=True)\n",
    "axes[1].plot(freq_uHz, window_some, \"k\", rasterized=True)\n",
    "axes[0].set_ylabel(\"window function\")\n",
    "axes[0].set_xlabel(\"frequency [$\\mu$Hz]\")\n",
    "axes[1].set_xlabel(\"frequency [$\\mu$Hz]\")\n",
    "axes[0].set_title(\"all data\")\n",
    "axes[1].set_title(\"subset of data\")\n",
    "[ax.set_yscale(\"log\") for ax in axes];\n",
    "fig.savefig(format_filename(\"window_function\"), bbox_inches=\"tight\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute $\\nu_\\mathrm{max}$ and $\\Delta \\nu$ from the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for name, ps in zip((\"subset of data\", \"all data\"), (power_some-bkg_some, power_all-bkg_all)):\n",
    "    # Compute the smoothed power spectrum\n",
    "    df = freq_uHz[1] - freq_uHz[0]\n",
    "    smoothed_ps = gaussian_filter(ps, 10 / df)\n",
    "\n",
    "    # And the autocorrelation function of a lightly smoothed power spectrum\n",
    "    acor_func = autocorr.function(gaussian_filter(ps, 0.5 / df))\n",
    "    lags = df*np.arange(len(acor_func))\n",
    "    acor_func = acor_func[lags < 30]\n",
    "    lags = lags[lags < 30]\n",
    "\n",
    "    # Find the peaks\n",
    "    def find_peaks(z):\n",
    "        peak_inds = (z[1:-1] > z[:-2]) * (z[1:-1] > z[2:])\n",
    "        peak_inds = np.arange(1, len(z)-1)[peak_inds]\n",
    "        peak_inds = peak_inds[np.argsort(z[peak_inds])][::-1]\n",
    "        return peak_inds\n",
    "\n",
    "    peak_freqs = freq_uHz[find_peaks(smoothed_ps)]\n",
    "    nu_max = peak_freqs[peak_freqs > 5][0]\n",
    "    \n",
    "    # Expected delta_nu: Stello et al (2009)\n",
    "    dnu_expected = 0.263 * nu_max ** 0.772\n",
    "    peak_lags = lags[find_peaks(acor_func)]\n",
    "    delta_nu = peak_lags[np.argmin(np.abs(peak_lags - dnu_expected))]\n",
    "    print(\"{0}: nu_max = {1}, delta_nu = {2}\".format(name, nu_max, delta_nu))\n",
    "\n",
    "    # Plot the smoothed power spectrum and autocorrelation function\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 3))\n",
    "    axes[0].plot(freq_uHz, smoothed_ps, \"k\")\n",
    "    axes[0].axvline(nu_max, color=\"g\")\n",
    "    axes[0].set_ylabel(\"smoothed power spectrum\")\n",
    "    axes[0].set_xlabel(\"frequency [$\\mu$Hz]\")\n",
    "\n",
    "    axes[1].plot(lags, acor_func, \"k\")\n",
    "    axes[1].axvline(delta_nu, color=\"g\")\n",
    "    axes[1].set_ylabel(\"autocorrelation function\")\n",
    "    axes[1].set_xlabel(\"frequency spacing [$\\mu$Hz]\")\n",
    "    axes[1].set_xlim(0, 30)\n",
    "    \n",
    "    for ax in axes:\n",
    "        ax.annotate(name, xy=(1, 1), xycoords=\"axes fraction\",\n",
    "                    xytext=(-5, -5), textcoords=\"offset points\",\n",
    "                    ha=\"right\", va=\"top\")\n",
    "    \n",
    "    fig.savefig(format_filename(\"numax_deltanu_\"+name.split()[0]), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the Gaussian Process model and find the maximum likelihood parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cached_param(f):\n",
    "    key = \"_\" + f.__name__\n",
    "    def wrapped(self):\n",
    "        if self.dirty or not hasattr(self, key):\n",
    "            setattr(self, key, f(self))\n",
    "        return getattr(self, key)\n",
    "    return wrapped\n",
    "\n",
    "class AsteroTerm(kernels.Kernel):\n",
    "    \n",
    "    parameter_names = (\n",
    "        \"log_S_g\", \"log_omega_g\", \"log_nu_max\", \"log_delta_nu\",\n",
    "        \"epsilon\", \"log_A\", \"log_Q\", \"log_W\",\n",
    "    )\n",
    "    \n",
    "    @property\n",
    "    def p_complex(self):\n",
    "        return 6\n",
    "    \n",
    "    @cached_param\n",
    "    def first_alpha(self):\n",
    "        return np.exp(self.log_S_g + self.log_omega_g) / np.sqrt(2.0)\n",
    "    \n",
    "    @cached_param\n",
    "    def first_beta(self):\n",
    "        return np.exp(self.log_omega_g) / np.sqrt(2.0)\n",
    "\n",
    "    @cached_param\n",
    "    def Q(self):\n",
    "        return 0.5 + np.exp(self.log_Q)\n",
    "    \n",
    "    @cached_param\n",
    "    def delta(self):\n",
    "        j = np.arange(-2, 3, 1)\n",
    "        return j*np.exp(self.log_delta_nu) + self.epsilon\n",
    "    \n",
    "    @cached_param\n",
    "    def omega(self):\n",
    "        return 2*np.pi * (np.exp(self.log_nu_max) + self.delta())\n",
    "    \n",
    "    @cached_param\n",
    "    def S(self):\n",
    "        return np.exp(self.log_A - 0.5*self.delta()**2*np.exp(2*self.log_W)) / self.Q()**2\n",
    "\n",
    "    @property\n",
    "    def alpha_complex_real(self):\n",
    "        return np.append(self.first_alpha(), self.S()*self.omega()*self.Q())\n",
    "\n",
    "    @property\n",
    "    def alpha_complex_imag(self):\n",
    "        Q = self.Q()\n",
    "        return np.append(self.first_alpha(), self.S()*self.omega()*Q/np.sqrt(4*Q*Q-1))\n",
    "\n",
    "    @property\n",
    "    def beta_complex_real(self):\n",
    "        return np.append(self.first_beta(), 0.5*self.omega()/self.Q())\n",
    "\n",
    "    @property\n",
    "    def beta_complex_imag(self):\n",
    "        Q = self.Q()\n",
    "        return np.append(self.first_beta(), 0.5*self.omega()/Q*np.sqrt(4*Q*Q-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up the GP model\n",
    "uHz_conv = 1e-6 * 24 * 60 * 60\n",
    "kernel = AsteroTerm(\n",
    "    5.0,\n",
    "    2.0,\n",
    "    np.log(nu_max*uHz_conv),        # log(nu_max)\n",
    "    np.log(delta_nu*uHz_conv),      # log(delta_nu)\n",
    "    0.0,                            # offset between nu_max and central freq. spike\n",
    "    9.0,                            # log(amp_max)\n",
    "    5.0,                            # log(q_factor)\n",
    "    np.log(delta_nu*uHz_conv),      # width of envelope\n",
    ")\n",
    "white_noise = 2.0*np.log(np.median(np.abs(np.diff(fit_y))))\n",
    "gp = genrp.GP(kernel, log_white_noise=white_noise, fit_white_noise=True)\n",
    "gp.compute(fit_x, fit_yerr)\n",
    "print(\"Initial log-likelihood: {0}\".format(gp.log_likelihood(fit_y)))\n",
    "\n",
    "# Optimize\n",
    "params = np.array(gp.get_parameter_vector())\n",
    "bounds = np.array([(None, None) for _ in range(len(p0))])\n",
    "bounds[3] = (params[3]-0.1, params[3]+0.1)\n",
    "bounds[4] = (params[4]-0.1, params[4]+0.1)\n",
    "\n",
    "param_mask = np.ones(len(params), dtype=bool)\n",
    "def nll(p):\n",
    "    params[param_mask] = p\n",
    "    gp.set_parameter_vector(params)\n",
    "    ll = gp.log_likelihood(fit_y)\n",
    "    if not np.isfinite(ll):\n",
    "        return 1e10\n",
    "    return (\n",
    "        -ll +\n",
    "        0.5*params[5]**2  # Regularize delta_nu_max_0 towards 0\n",
    "    )\n",
    "\n",
    "# Maximimize the non-periodic components\n",
    "param_mask[:] = False\n",
    "param_mask[:3] = True\n",
    "r = minimize(nll, params[param_mask], method=\"L-BFGS-B\")\n",
    "params[param_mask] = r.x\n",
    "print(r.success, r.fun, np.exp(params[3:5])/uHz_conv)\n",
    "\n",
    "# Grid initialize\n",
    "param_mask[:] = True\n",
    "# param_mask[6] = False\n",
    "params0 = np.array(params)\n",
    "best = (np.inf, np.array(params))\n",
    "for lnmx in params[3] + np.linspace(-0.05, 0.05, 5):\n",
    "    params = np.array(params0)\n",
    "    params[3] = lnmx\n",
    "    params[4] = np.log(0.263 * (np.exp(lnmx)/uHz_conv) ** 0.772 * uHz_conv)\n",
    "    r = minimize(nll, params[param_mask], method=\"L-BFGS-B\", bounds=bounds[param_mask])\n",
    "    params[param_mask] = r.x\n",
    "    print(r.success, r.fun, np.exp(params[3:5])/uHz_conv)\n",
    "    if r.fun < best[0]:\n",
    "        best = (r.fun, params)\n",
    "params = best[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gp.set_parameter_vector(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 3), sharey=True)\n",
    "ax.plot(freq_uHz, np.sqrt(power_all), \"k\", alpha=0.8)\n",
    "ax.plot(freq_uHz, gp.kernel.get_psd(2*np.pi*freq), \"g\", alpha=0.5)\n",
    "ax.set_xlabel(\"frequency [$\\mu$Hz]\")\n",
    "ax.set_ylabel(\"power\")\n",
    "ax.set_yscale(\"log\")\n",
    "fig.savefig(format_filename(\"intial_psd\"), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lnprob(p):\n",
    "    if np.any(p[:5] < -15.0) or np.any(p[:5] > 15.0):\n",
    "        return -np.inf\n",
    "    if np.any(p[6:] < -15.0) or np.any(p[6:] > 15.0):\n",
    "        return -np.inf\n",
    "    gp.set_parameter_vector(p)\n",
    "    ll = gp.log_likelihood(fit_y)\n",
    "    if not np.isfinite(ll):\n",
    "        return -np.inf\n",
    "    return ll - 0.5 * p[5]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def astero_move_1(rng, x0):\n",
    "    x = np.array(x0)\n",
    "    f = 2.0 * (rng.rand(len(x)) < 0.5) - 1.0\n",
    "    x[:, 3] = np.log(np.exp(x[:, 3]) + f * np.exp(x[:, 4]))\n",
    "    return x, np.zeros(len(x))\n",
    "\n",
    "# def astero_move_2(rng, x0):\n",
    "#     x = np.array(x0)\n",
    "#     f = rng.randn(len(x)) * np.exp(x[:, 4])\n",
    "#     x[:, 3] = np.log(np.exp(x[:, 3]) + f)\n",
    "#     x[:, 5] = x[:, 5] - f\n",
    "#     return x, np.zeros(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampler = emcee3.Sampler([\n",
    "    emcee3.moves.StretchMove(),\n",
    "    emcee3.moves.DEMove(1e-3),\n",
    "    emcee3.moves.KDEMove(),\n",
    "    emcee3.moves.MHMove(astero_move_1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ensemble = emcee3.Ensemble(emcee3.SimpleModel(lnprob), initial_samples,\n",
    "                           pool=emcee3.pools.InterruptiblePool())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ensemble = sampler.run(ensemble, 1000, progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampler.acceptance_fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(sampler.get_coords()[:, :, 3], color=\"k\", alpha=0.3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples = sampler.get_coords(flat=True, discard= 500)\n",
    "resampled = samples[np.random.randint(len(samples), size=100)]\n",
    "sampler2 = emcee3.Sampler([\n",
    "    (emcee3.moves.StretchMove(), 2),\n",
    "    (emcee3.moves.DEMove(1e-3), 1),\n",
    "    # (emcee3.moves.KDEMove(), 4),\n",
    "    (emcee3.moves.MHMove(astero_move), 0.5),\n",
    "])\n",
    "ensemble2 = emcee3.Ensemble(emcee3.SimpleModel(lnprob), resampled,\n",
    "                            pool=emcee3.pools.InterruptiblePool())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ensemble2 = sampler2.run(ensemble2, 500, progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampler2.acceptance_fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(sampler2.get_coords()[:, :, 5], color=\"k\", alpha=0.3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "autocorr.integrated_time(np.mean(sampler.get_coords(discard=300), axis=1), c=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time_grid = np.linspace(0, 1.4, 5000)\n",
    "psds = []\n",
    "acors = []\n",
    "envs = []\n",
    "samples = sampler.get_coords(discard=300, flat=True)\n",
    "for s in samples[np.random.randint(len(samples), size=1000)]:\n",
    "#     s = np.array(s)\n",
    "#     s[7] = 2*s[4]\n",
    "    gp.set_parameter_vector(s)\n",
    "    psds.append(gp.kernel.get_psd(2*np.pi*freq))\n",
    "    acors.append(gp.kernel.get_value(time_grid))\n",
    "    envs.append(0.5*np.log(2./np.pi) + s[5] - 0.5*(freq - np.exp(s[3]))**2 * np.exp(-s[7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q = np.percentile(acors, [16, 50, 84], axis=0)\n",
    "plt.fill_between(time_grid * 24, q[0], q[2], color=\"k\", alpha=0.3)\n",
    "plt.plot(time_grid * 24, q[1], \"k\", alpha=0.8)\n",
    "plt.xlabel(r\"$\\tau$ [hours]\")\n",
    "plt.ylabel(r\"$C(\\tau)$\")\n",
    "plt.savefig(format_filename(\"acor\"), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q = np.percentile(psds, [16, 50, 84], axis=0)\n",
    "plt.fill_between(freq_uHz, q[0], q[2], color=\"k\", alpha=0.3)\n",
    "plt.plot(freq_uHz, q[1], \"k\", alpha=0.8)\n",
    "plt.yscale(\"log\")\n",
    "ylim = plt.gca().get_ylim()\n",
    "\n",
    "# q = np.percentile(np.exp(envs), [16, 50, 84], axis=0)\n",
    "# plt.fill_between(freq_uHz, q[0], q[2], color=\"g\", alpha=0.3)\n",
    "# plt.plot(freq_uHz, q[1], \"g\", alpha=0.8)\n",
    "plt.ylim(ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = np.exp(samples[:, 3:5])/uHz_conv\n",
    "nu_max_pub = 171.94, 3.62\n",
    "delta_nu_pub = 13.28, 0.29\n",
    "fig = corner.corner(s, smooth=0.7, smooth1d=1.0);\n",
    "fig.axes[2].errorbar(nu_max_pub[0], delta_nu_pub[0], xerr=nu_max_pub[1], yerr=delta_nu_pub[1],\n",
    "                     fmt=\".\", color=\"r\", capsize=0, lw=2, mec=\"none\")\n",
    "fig.savefig(format_filename(\"numax_deltanu_corner\"), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corner.corner(samples);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 1, sharex=True, figsize=(5, 8))\n",
    "\n",
    "axes[0].plot(freq_uHz, np.sqrt(power_all), \"k\", alpha=0.3)\n",
    "axes[0].plot(freq_uHz, np.sqrt(gaussian_filter(power_all, 5)), \"k\")\n",
    "\n",
    "axes[1].plot(freq_uHz, np.sqrt(power_some), \"k\", alpha=0.3)\n",
    "axes[1].plot(freq_uHz, np.sqrt(gaussian_filter(power_some, 5)), \"k\")\n",
    "\n",
    "q = np.percentile(psds, [16, 50, 84], axis=0)\n",
    "axes[2].fill_between(freq_uHz, q[0], q[2], color=\"k\", alpha=0.3)\n",
    "axes[2].plot(freq_uHz, q[1], \"k\", alpha=0.8)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_yscale(\"log\")\n",
    "\n",
    "frac = 100 * len(fit_x) / len(x)\n",
    "axes[0].set_ylabel(\"periodogram; all data\")\n",
    "axes[1].set_ylabel(\"periodogram; {0:.0f}\\% of data\".format(frac))\n",
    "axes[2].set_ylabel(\"posterior psd; {0:.0f}\\% of data\".format(frac))\n",
    "axes[2].set_xlabel(\"frequency [$\\mu$Hz]\")\n",
    "\n",
    "fig.savefig(format_filename(\"comparisons\"), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
